{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ee443e",
   "metadata": {},
   "source": [
    "Create a sentiment classifier for reviews\n",
    "Use the reviews from publicly available Internet Movie Databse IMDB dataset that consists of 50k reviews\n",
    "Half are training & half are validation\n",
    "Total 10 stars, below/equal to 4 = bad and above 7 is good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe89fd",
   "metadata": {},
   "source": [
    "Compare between: 1.Dense, 2. SimpleRNN, 3. Bidirectional RNN, 4. Stacked, 5.LSTM, 6. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc53566e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM, GRU, SimpleRNN\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae3d4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output directory\n",
    "output_dir = 'model_output/rnn'\n",
    "\n",
    "#training\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "#embedding:\n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "n_words_to_skip = 50     # % of data to split for train & validation\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a3393be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple RNN\n",
    "n_rnn = 256\n",
    "drop_rnn = 0.2\n",
    "\n",
    "#LSTM/Bi\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2\n",
    "\n",
    "#stacked\n",
    "n_lstm_1 = 64\n",
    "n_lstm_2 = 64\n",
    "drop2_lstm = 0.2\n",
    "\n",
    "#GRU\n",
    "n_gru = 256\n",
    "drop_gru = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17166632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IMDB dataset is not readable , but with full of number values\n",
    "# Here the split for train & test is done. top 50% assigned to train and the rest is to test\n",
    "\n",
    "(x_train,y_train), (x_valid, y_valid) = imdb.load_data(num_words = n_unique_words)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b76be71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 100, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 256)               82176     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722,433\n",
      "Trainable params: 722,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simple RNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length = max_review_length)) # Embedding layer, create word vectors , size =n_unique_words,\n",
    "                                                                            # dimension\n",
    "model.add(SpatialDropout1D(drop_embed))  \n",
    "model.add(SimpleRNN(n_rnn, dropout=drop_rnn))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output layer we need to have only one output , as to have either good or bad \n",
    "                                            #and we have to use sigmoid for the binary classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5713115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_7 (Spatia  (None, 100, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               328704    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 968,961\n",
      "Trainable params: 968,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length = max_review_length)) # Embedding layer, create word vectors , size =n_unique_words,\n",
    "                                                                            # dimension\n",
    "model.add(SpatialDropout1D(drop_embed))  \n",
    "model.add(LSTM(n_lstm, dropout=drop_lstm))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output layer we need to have only one output , as to have either good or bad \n",
    "                                            #and we have to use sigmoid for the binary classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a8b0194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spatia  (None, 100, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 512)              657408    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297,921\n",
      "Trainable params: 1,297,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length = max_review_length)) # Embedding layer, create word vectors , size =n_unique_words,\n",
    "                                                                            # dimension\n",
    "model.add(SpatialDropout1D(drop_embed))  \n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output layer we need to have only one output , as to have either good or bad \n",
    "                                            #and we have to use sigmoid for the binary classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc738c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_4 (Spatia  (None, 100, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 256)               247296    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 887,553\n",
      "Trainable params: 887,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length = max_review_length)) # Embedding layer, create word vectors , size =n_unique_words,\n",
    "                                                                            # dimension\n",
    "model.add(SpatialDropout1D(drop_embed))  \n",
    "model.add(GRU(n_gru, dropout=drop_gru))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output layer we need to have only one output , as to have either good or bad \n",
    "                                            #and we have to use sigmoid for the binary classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "476d18f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_6 (Spatia  (None, 100, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 100, 128)         66048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 804,993\n",
      "Trainable params: 804,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stacked\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length = max_review_length)) # Embedding layer, create word vectors , size =n_unique_words,\n",
    "                                                                            # dimension\n",
    "model.add(SpatialDropout1D(drop_embed))  \n",
    "model.add(Bidirectional(LSTM(n_lstm_1, dropout=drop_lstm, return_sequences=True))) #Since stacked, we have a return sequence true\n",
    "model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output layer we need to have only one output , as to have either good or bad \n",
    "                                            #and we have to use sigmoid for the binary classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381f34d",
   "metadata": {},
   "source": [
    "Here you can see the number values based on the frequency of words occured\n",
    "0 : Padding\n",
    "1 : Starting Token - starting of review data\n",
    "2 : Tokens that occur very frequently across the corpus(top 50)\n",
    "3 : Most frequently occuring word in the corpus\n",
    "4 : The second-most frequently occuring word\n",
    "5 : The third-most frequently occuring word and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bfcfd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # binary we used to classify o & 1\n",
    "modelcheckpoint = ModelCheckpoint(filepath = output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8bd08b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 132s 663ms/step - loss: 0.5596 - accuracy: 0.6933 - val_loss: 0.3567 - val_accuracy: 0.8444\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 133s 678ms/step - loss: 0.3037 - accuracy: 0.8726 - val_loss: 0.3526 - val_accuracy: 0.8498\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 125s 640ms/step - loss: 0.2405 - accuracy: 0.9051 - val_loss: 0.3535 - val_accuracy: 0.8485\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 125s 639ms/step - loss: 0.1990 - accuracy: 0.9242 - val_loss: 0.4028 - val_accuracy: 0.8454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d501162e80>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size = batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid,y_valid),\n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c97625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#evaluate\n",
    "model.load_weights(output_dir+\"/weights.02.hdf5\") #NOT zero-indexed\n",
    "#y_hat = model.predict(x_valid)\n",
    "#predict_proba=model.predict([x_valid])\n",
    "#y_hat=np.argmax(predict_proba,axis=1)\n",
    "\n",
    "predict_x=model.predict(x_valid)\n",
    "y_hat=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "235650ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "267a4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbed4af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50.00'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce12149c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11016/3215667960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfloat_y_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfloat_y_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91124d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Sara)",
   "language": "python",
   "name": "sara"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
