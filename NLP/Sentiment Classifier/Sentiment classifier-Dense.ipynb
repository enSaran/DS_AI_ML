{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ee443e",
   "metadata": {},
   "source": [
    "Create a sentiment classifier for reviews\n",
    "Use the reviews from publicly available Internet Movie Databse IMDB dataset that consists of 50k reviews\n",
    "Half are training & half are validation\n",
    "Total 10 stars, below/equal to 4 = bad and above 7 is good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe89fd",
   "metadata": {},
   "source": [
    "Compare between: 1.Dense, 2. SimpleRNN, 3. Bidirectional RNN, 4. Stacked, 5.LSTM, 6. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc53566e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3d4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output directory\n",
    "output_dir = 'model_output/dense'\n",
    "\n",
    "#training\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "#embedding:\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "n_words_to_skip = 50     # % of data to split for train & validation\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "\n",
    "#dense - Parameters for Dense neural layer\n",
    "n_dense = 64\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21772c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IMDB dataset is not readable , but with full of number values\n",
    "# Here the split for train & test is done. top 50% assigned to train and the rest is to test\n",
    "\n",
    "(x_train,y_train), (x_valid,y_valid) = imdb.load_data(num_words = n_unique_words, skip_top = n_words_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb9ee56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]),\n",
       "       list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95]),\n",
       "       list([2, 2, 2, 2, 2, 2, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 2, 71, 149, 2, 2, 112, 2, 2401, 311, 2, 2, 3711, 2, 75, 2, 1829, 296, 2, 86, 320, 2, 534, 2, 263, 4821, 1301, 2, 1873, 2, 89, 78, 2, 66, 2, 2, 360, 2, 2, 58, 316, 334, 2, 2, 1716, 2, 645, 662, 2, 257, 85, 1200, 2, 1228, 2578, 83, 68, 3912, 2, 2, 165, 1539, 278, 2, 69, 2, 780, 2, 106, 2, 2, 1338, 2, 2, 2, 2, 215, 2, 610, 2, 2, 87, 326, 2, 2300, 2, 2, 2, 2, 272, 2, 57, 2, 2, 2, 2, 2, 2, 2307, 51, 2, 170, 2, 595, 116, 595, 1352, 2, 191, 79, 638, 89, 2, 2, 2, 2, 106, 607, 624, 2, 534, 2, 227, 2, 129, 113]),\n",
       "       list([2, 2, 2, 2, 2, 2804, 2, 2040, 432, 111, 153, 103, 2, 1494, 2, 70, 131, 67, 2, 61, 2, 744, 2, 3715, 761, 61, 2, 452, 2, 2, 985, 2, 2, 59, 166, 2, 105, 216, 1239, 2, 1797, 2, 2, 2, 2, 744, 2413, 2, 2, 2, 687, 2, 2, 2, 2, 2, 3693, 2, 2, 2, 121, 59, 456, 2, 2, 2, 265, 2, 575, 111, 153, 159, 59, 2, 1447, 2, 2, 586, 482, 2, 2, 96, 59, 716, 2, 2, 172, 65, 2, 579, 2, 2, 2, 1615, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 464, 2, 314, 2, 2, 2, 719, 605, 2, 2, 202, 2, 310, 2, 3772, 3501, 2, 2722, 58, 2, 2, 537, 2116, 180, 2, 2, 413, 173, 2, 263, 112, 2, 152, 377, 2, 537, 263, 846, 579, 178, 54, 75, 71, 476, 2, 413, 263, 2504, 182, 2, 2, 75, 2306, 922, 2, 279, 131, 2895, 2, 2867, 2, 2, 2, 921, 2, 192, 2, 1219, 3890, 2, 2, 217, 4122, 1710, 537, 2, 1236, 2, 736, 2, 2, 61, 403, 2, 2, 2, 61, 4494, 2, 2, 4494, 159, 90, 263, 2311, 4319, 309, 2, 178, 2, 82, 4319, 2, 65, 2, 2, 145, 143, 2, 2, 2, 537, 746, 537, 537, 2, 2, 2, 2, 594, 2, 2, 94, 2, 3987, 2, 2, 2, 2, 538, 2, 1795, 246, 2, 2, 2, 2, 635, 2, 2, 51, 408, 2, 94, 318, 1382, 2, 2, 2, 2683, 936, 2, 2, 2, 2, 2, 2, 2, 1885, 2, 1118, 2, 80, 126, 842, 2, 2, 2, 2, 4726, 2, 4494, 2, 1550, 3633, 159, 2, 341, 2, 2733, 2, 4185, 173, 2, 90, 2, 2, 2, 2, 2, 1784, 86, 1117, 2, 3261, 2, 2, 2, 2, 2, 2, 2841, 2, 2, 1010, 2, 793, 2, 2, 1386, 1830, 2, 2, 246, 50, 2, 2, 2750, 1944, 746, 90, 2, 2, 2, 124, 2, 882, 2, 882, 496, 2, 2, 2213, 537, 121, 127, 1219, 130, 2, 2, 494, 2, 124, 2, 882, 496, 2, 341, 2, 2, 846, 2, 2, 2, 2, 1906, 2, 97, 2, 236, 2, 1311, 2, 2, 2, 2, 2, 2, 2, 91, 2, 3987, 70, 2, 882, 2, 579, 2, 2, 2, 2, 2, 537, 2, 2, 2, 2, 65, 2, 537, 75, 2, 1775, 3353, 2, 1846, 2, 2, 2, 154, 2, 2, 518, 53, 2, 2, 2, 3211, 882, 2, 399, 2, 75, 257, 3807, 2, 2, 2, 2, 456, 2, 65, 2, 2, 205, 113, 2, 2, 2, 2, 2, 2, 2, 242, 2, 91, 1202, 2, 2, 2070, 307, 2, 2, 2, 126, 93, 2, 2, 2, 188, 1076, 3222, 2, 2, 2, 2, 2348, 537, 2, 53, 537, 2, 82, 2, 2, 2, 2, 2, 280, 2, 219, 2, 2, 431, 758, 859, 2, 953, 1052, 2, 2, 2, 2, 94, 2, 2, 238, 60, 2, 2, 2, 804, 2, 2, 2, 2, 132, 2, 67, 2, 2, 2, 2, 283, 2, 2, 2, 2, 2, 242, 955, 2, 2, 279, 2, 2, 2, 1685, 195, 2, 238, 60, 796, 2, 2, 671, 2, 2804, 2, 2, 559, 154, 888, 2, 726, 50, 2, 2, 2, 2, 566, 2, 579, 2, 64, 2574]),\n",
       "       list([2, 249, 1323, 2, 61, 113, 2, 2, 2, 1637, 2, 2, 56, 2, 2401, 2, 457, 88, 2, 2626, 1400, 2, 3171, 2, 70, 79, 2, 706, 919, 2, 2, 355, 340, 355, 1696, 96, 143, 2, 2, 2, 289, 2, 61, 369, 71, 2359, 2, 2, 2, 131, 2073, 249, 114, 249, 229, 249, 2, 2, 2, 126, 110, 2, 473, 2, 569, 61, 419, 56, 429, 2, 1513, 2, 2, 534, 95, 474, 570, 2, 2, 124, 138, 88, 2, 421, 1543, 52, 725, 2, 61, 419, 2, 2, 1571, 2, 1543, 2, 2, 2, 2, 2, 296, 2, 3524, 2, 2, 421, 128, 74, 233, 334, 207, 126, 224, 2, 562, 298, 2167, 1272, 2, 2601, 2, 516, 988, 2, 2, 79, 120, 2, 595, 2, 784, 2, 3171, 2, 165, 170, 143, 2, 2, 2, 2, 2, 226, 251, 2, 61, 113]),\n",
       "       list([2, 778, 128, 74, 2, 630, 163, 2, 2, 1766, 2, 1051, 2, 2, 85, 156, 2, 2, 148, 139, 121, 664, 665, 2, 2, 1361, 173, 2, 749, 2, 2, 3804, 2, 2, 226, 65, 2, 2, 127, 2, 2, 2, 2])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 6 records of train data\n",
    "\n",
    "x_train[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7585b",
   "metadata": {},
   "source": [
    "Here you can see the number values based on the frequency of words occured\n",
    "0 : Padding\n",
    "1 : Starting Token - starting of review data\n",
    "2 : Tokens that occur very frequently across the corpus(top 50)\n",
    "3 : Most frequently occuring word in the corpus\n",
    "4 : The second-most frequently occuring word\n",
    "5 : The third-most frequently occuring word and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c5ea63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n",
      "141\n",
      "550\n",
      "147\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "# Get length of first 6 recs \n",
    "\n",
    "for x in x_train[0:6]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f809bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 6 values of target feature ie Good=1 Bad=0\n",
    "\n",
    "y_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd45c441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of train & test\n",
    "\n",
    "len(x_train), len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e15786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the word index, we try to label the zero-PADding, START of review and UNKnown values\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"PAD\"] = 0\n",
    "word_index[\"START\"] = 1\n",
    "word_index[\"UNK\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f554e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72dbefa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 2,\n",
       " 173,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 100,\n",
       " 2,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 284,\n",
       " 2,\n",
       " 150,\n",
       " 2,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 2,\n",
       " 2,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 2,\n",
       " 546,\n",
       " 2,\n",
       " 2,\n",
       " 447,\n",
       " 2,\n",
       " 192,\n",
       " 50,\n",
       " 2,\n",
       " 2,\n",
       " 147,\n",
       " 2025,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 2,\n",
       " 2,\n",
       " 71,\n",
       " 87,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 2,\n",
       " 76,\n",
       " 2,\n",
       " 2,\n",
       " 1247,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 515,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 626,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 62,\n",
       " 386,\n",
       " 2,\n",
       " 2,\n",
       " 316,\n",
       " 2,\n",
       " 106,\n",
       " 2,\n",
       " 2,\n",
       " 2223,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 2,\n",
       " 2,\n",
       " 130,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 619,\n",
       " 2,\n",
       " 2,\n",
       " 124,\n",
       " 51,\n",
       " 2,\n",
       " 135,\n",
       " 2,\n",
       " 2,\n",
       " 1415,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 215,\n",
       " 2,\n",
       " 77,\n",
       " 52,\n",
       " 2,\n",
       " 2,\n",
       " 407,\n",
       " 2,\n",
       " 82,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3766,\n",
       " 2,\n",
       " 723,\n",
       " 2,\n",
       " 71,\n",
       " 2,\n",
       " 530,\n",
       " 476,\n",
       " 2,\n",
       " 400,\n",
       " 317,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1029,\n",
       " 2,\n",
       " 104,\n",
       " 88,\n",
       " 2,\n",
       " 381,\n",
       " 2,\n",
       " 297,\n",
       " 98,\n",
       " 2,\n",
       " 2071,\n",
       " 56,\n",
       " 2,\n",
       " 141,\n",
       " 2,\n",
       " 194,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 226,\n",
       " 2,\n",
       " 2,\n",
       " 134,\n",
       " 476,\n",
       " 2,\n",
       " 480,\n",
       " 2,\n",
       " 144,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 51,\n",
       " 2,\n",
       " 2,\n",
       " 224,\n",
       " 92,\n",
       " 2,\n",
       " 104,\n",
       " 2,\n",
       " 226,\n",
       " 65,\n",
       " 2,\n",
       " 2,\n",
       " 1334,\n",
       " 88,\n",
       " 2,\n",
       " 2,\n",
       " 283,\n",
       " 2,\n",
       " 2,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 178,\n",
       " 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "991083f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the review with labelled data\n",
    "' '.join(index_word[id] for id in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c0e1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the actual review data from IMDB\n",
    "\n",
    "(all_x_train,_),(all_x_valid,_) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d4bfcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the actaul review at first index\n",
    "\n",
    "' '.join(index_word[id] for id in all_x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44fef79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize to have same lengths of the reviews\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length,\n",
    "                       padding = pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length,\n",
    "                       padding = pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02e23889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,    2,    2,    2,    2,  215,    2,   77,   52,    2,    2,\n",
       "         407,    2,   82,    2,    2,    2,  107,  117,    2,    2,  256,\n",
       "           2,    2,    2, 3766,    2,  723,    2,   71,    2,  530,  476,\n",
       "           2,  400,  317,    2,    2,    2,    2, 1029,    2,  104,   88,\n",
       "           2,  381,    2,  297,   98,    2, 2071,   56,    2,  141,    2,\n",
       "         194,    2,    2,    2,  226,    2,    2,  134,  476,    2,  480,\n",
       "           2,  144,    2,    2,    2,   51,    2,    2,  224,   92,    2,\n",
       "         104,    2,  226,   65,    2,    2, 1334,   88,    2,    2,  283,\n",
       "           2,    2, 4472,  113,  103,    2,    2,    2,    2,    2,  178,\n",
       "           2],\n",
       "       [ 163,    2, 3215,    2,    2, 1153,    2,  194,  775,    2,    2,\n",
       "           2,  349, 2637,  148,  605,    2,    2,    2,  123,  125,   68,\n",
       "           2,    2,    2,  349,  165, 4362,   98,    2,    2,  228,    2,\n",
       "           2,    2, 1157,    2,  299,  120,    2,  120,  174,    2,  220,\n",
       "         175,  136,   50,    2, 4373,  228,    2,    2,    2,  656,  245,\n",
       "        2350,    2,    2,    2,  131,  152,  491,    2,    2,    2,    2,\n",
       "        1212,    2,    2,    2,  371,   78,    2,  625,   64, 1382,    2,\n",
       "           2,  168,  145,    2,    2, 1690,    2,    2,    2, 1355,    2,\n",
       "           2,    2,   52,  154,  462,    2,   89,   78,  285,    2,  145,\n",
       "          95],\n",
       "       [1301,    2, 1873,    2,   89,   78,    2,   66,    2,    2,  360,\n",
       "           2,    2,   58,  316,  334,    2,    2, 1716,    2,  645,  662,\n",
       "           2,  257,   85, 1200,    2, 1228, 2578,   83,   68, 3912,    2,\n",
       "           2,  165, 1539,  278,    2,   69,    2,  780,    2,  106,    2,\n",
       "           2, 1338,    2,    2,    2,    2,  215,    2,  610,    2,    2,\n",
       "          87,  326,    2, 2300,    2,    2,    2,    2,  272,    2,   57,\n",
       "           2,    2,    2,    2,    2,    2, 2307,   51,    2,  170,    2,\n",
       "         595,  116,  595, 1352,    2,  191,   79,  638,   89,    2,    2,\n",
       "           2,    2,  106,  607,  624,    2,  534,    2,  227,    2,  129,\n",
       "         113],\n",
       "       [   2,    2,    2,  188, 1076, 3222,    2,    2,    2,    2, 2348,\n",
       "         537,    2,   53,  537,    2,   82,    2,    2,    2,    2,    2,\n",
       "         280,    2,  219,    2,    2,  431,  758,  859,    2,  953, 1052,\n",
       "           2,    2,    2,    2,   94,    2,    2,  238,   60,    2,    2,\n",
       "           2,  804,    2,    2,    2,    2,  132,    2,   67,    2,    2,\n",
       "           2,    2,  283,    2,    2,    2,    2,    2,  242,  955,    2,\n",
       "           2,  279,    2,    2,    2, 1685,  195,    2,  238,   60,  796,\n",
       "           2,    2,  671,    2, 2804,    2,    2,  559,  154,  888,    2,\n",
       "         726,   50,    2,    2,    2,    2,  566,    2,  579,    2,   64,\n",
       "        2574],\n",
       "       [   2,    2,  131, 2073,  249,  114,  249,  229,  249,    2,    2,\n",
       "           2,  126,  110,    2,  473,    2,  569,   61,  419,   56,  429,\n",
       "           2, 1513,    2,    2,  534,   95,  474,  570,    2,    2,  124,\n",
       "         138,   88,    2,  421, 1543,   52,  725,    2,   61,  419,    2,\n",
       "           2, 1571,    2, 1543,    2,    2,    2,    2,    2,  296,    2,\n",
       "        3524,    2,    2,  421,  128,   74,  233,  334,  207,  126,  224,\n",
       "           2,  562,  298, 2167, 1272,    2, 2601,    2,  516,  988,    2,\n",
       "           2,   79,  120,    2,  595,    2,  784,    2, 3171,    2,  165,\n",
       "         170,  143,    2,    2,    2,    2,    2,  226,  251,    2,   61,\n",
       "         113],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,  778,  128,   74,    2,  630,  163,    2,    2,\n",
       "        1766,    2, 1051,    2,    2,   85,  156,    2,    2,  148,  139,\n",
       "         121,  664,  665,    2,    2, 1361,  173,    2,  749,    2,    2,\n",
       "        3804,    2,    2,  226,   65,    2,    2,  127,    2,    2,    2,\n",
       "           2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a55b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Now all reviews are of length 100\n",
    "for x in x_train[0:6]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d61bd7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15c85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 64)           320000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                409664    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 729,729\n",
      "Trainable params: 729,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length = max_review_length)) # Embedding layer, create word vectors , size =n_unique_words,\n",
    "                                                                            # dimension\n",
    "model.add(Flatten())  # To convert into one dimension\n",
    "model.add(Dense(n_dense, activation = 'relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output layer we need to have only one output , as to have either good or bad \n",
    "                                            #and we have to use sigmoid for the binary classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff4db55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5000, 320000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim, n_unique_words, n_dim * n_unique_words # embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b3ecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64, 6400)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_review_length, n_dim, n_dim * max_review_length #flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d15f782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 409664)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dense, n_dim*max_review_length*n_dense + n_dense #dense: weights + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ebb090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dense +1 #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b935fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) # binary we used to classify o & 1\n",
    "modelcheckpoint = ModelCheckpoint(filepath = output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d717071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 5s 22ms/step - loss: 0.5446 - accuracy: 0.6966 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.2672 - accuracy: 0.8955 - val_loss: 0.3531 - val_accuracy: 0.8439\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1038 - accuracy: 0.9710 - val_loss: 0.4454 - val_accuracy: 0.8313\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 0.0214 - accuracy: 0.9967 - val_loss: 0.5355 - val_accuracy: 0.8318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5550c3c10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size = batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid,y_valid),\n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "343ec0bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11016/1862425273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/weights.02.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#NOT zero-indexed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#predict_proba=model.predict([x_valid])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#y_hat=np.argmax(predict_proba,axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#evaluate\n",
    "model.load_weights(output_dir+\"/weights.02.hdf5\") #NOT zero-indexed\n",
    "y_hat = model.predict_proba(x_valid)\n",
    "#predict_proba=model.predict([x_valid])\n",
    "#y_hat=np.argmax(predict_proba,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6708268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab597f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa599488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50.00'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0f51fc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11016/3215667960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfloat_y_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfloat_y_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b48a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Sara)",
   "language": "python",
   "name": "sara"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
